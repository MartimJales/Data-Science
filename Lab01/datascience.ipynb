{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0q2iG91LFRrg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dslabs_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "id": "v7OA4RAbFuIn",
    "outputId": "8e0f8e1a-e7c2-4ae2-fdbc-3e0fb79723c5"
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "\n",
    "filename = \"data/CFD.csv\"\n",
    "target = \"CLASS\"\n",
    "file_tag = \"CFD\"\n",
    "file = \"CFD\"\n",
    "data: DataFrame = read_csv(filename, na_values=\"\")\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab01 - Data Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure, savefig, show\n",
    "from dslabs_functions import plot_bar_chart\n",
    "\n",
    "figure(figsize=(4, 2))\n",
    "values: dict[str, int] = {\"nr records\": data.shape[0], \"nr variables\": data.shape[1]}\n",
    "plot_bar_chart(\n",
    "    list(values.keys()), list(values.values()), title=\"Nr of records vs nr variables\"\n",
    ")\n",
    "savefig(f\"images/{file_tag}_records_variables.png\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, to_numeric, to_datetime\n",
    "\n",
    "\n",
    "def get_variable_types(df: DataFrame) -> dict[str, list]:\n",
    "    variable_types: dict = {\"numeric\": [], \"binary\": [], \"date\": [], \"symbolic\": []}\n",
    "\n",
    "    nr_values: Series = df.nunique(axis=0, dropna=True)\n",
    "    for c in df.columns:\n",
    "        if 2 == nr_values[c]:\n",
    "            variable_types[\"binary\"].append(c)\n",
    "            df[c].astype(\"bool\")\n",
    "        else:\n",
    "            try:\n",
    "                to_numeric(df[c], errors=\"raise\")\n",
    "                variable_types[\"numeric\"].append(c)\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    df[c] = to_datetime(df[c], errors=\"raise\")\n",
    "                    variable_types[\"date\"].append(c)\n",
    "                except ValueError:\n",
    "                    variable_types[\"symbolic\"].append(c)\n",
    "\n",
    "    return variable_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_types: dict[str, list] = get_variable_types(data)\n",
    "print(variable_types)\n",
    "counts: dict[str, int] = {}\n",
    "for tp in variable_types.keys():\n",
    "    counts[tp] = len(variable_types[tp])\n",
    "\n",
    "figure(figsize=(4, 2))\n",
    "plot_bar_chart(\n",
    "    list(counts.keys()), list(counts.values()), title=\"Nr of variables per type\"\n",
    ")\n",
    "savefig(f\"images/{file_tag}_variable_types.png\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv: dict[str, int] = {}\n",
    "for var in data.columns:\n",
    "    nr: int = data[var].isna().sum()\n",
    "    if nr > 0:\n",
    "        mv[var] = nr\n",
    "\n",
    "figure()\n",
    "plot_bar_chart(\n",
    "    list(mv.keys()),\n",
    "    list(mv.values()),\n",
    "    title=\"Nr of missing values per variable\",\n",
    "    xlabel=\"variables\",\n",
    "    ylabel=\"nr missing values\",\n",
    ")\n",
    "savefig(f\"images/{file_tag}_mv.png\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Granularity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_types: dict[str, list] = get_variable_types(data)\n",
    "print(variable_types)\n",
    "counts: dict[str, int] = {}\n",
    "for tp in variable_types.keys():\n",
    "    counts[tp] = len(variable_types[tp])\n",
    "\n",
    "figure(figsize=(4, 2))\n",
    "plot_bar_chart(\n",
    "    list(counts.keys()), list(counts.values()), title=\"Nr of variables per type\"\n",
    ")\n",
    "savefig(f\"images/{file_tag}_variable_types.png\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary5: DataFrame = data.describe(include=\"all\")\n",
    "summary5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_types: dict[str, list] = get_variable_types(data)\n",
    "numeric: list[str] = variables_types[\"numeric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import savefig, show\n",
    "from dslabs_functions import get_variable_types\n",
    "\n",
    "variables_types: dict[str, list] = get_variable_types(data)\n",
    "numeric: list[str] = variables_types[\"numeric\"]\n",
    "if [] != numeric:\n",
    "    data[numeric].boxplot(rot=45)\n",
    "    savefig(f\"images/{file_tag}_global_boxplot.png\")\n",
    "    show()\n",
    "else:\n",
    "    print(\"There are no numeric variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.pyplot import savefig, show, subplots\n",
    "from dslabs_functions import define_grid, HEIGHT\n",
    "\n",
    "if [] != numeric:\n",
    "    rows: int\n",
    "    cols: int\n",
    "    rows, cols = define_grid(len(numeric))\n",
    "    fig: Figure\n",
    "    axs: ndarray\n",
    "    fig, axs = subplots(\n",
    "        rows, cols, figsize=(cols * HEIGHT, rows * HEIGHT), squeeze=False\n",
    "    )\n",
    "    i, j = 0, 0\n",
    "    for n in range(len(numeric)):\n",
    "        axs[i, j].set_title(\"Boxplot for %s\" % numeric[n])\n",
    "        axs[i, j].boxplot(data[numeric[n]].dropna().values)\n",
    "        i, j = (i + 1, 0) if (n + 1) % cols == 0 else (i, j + 1)\n",
    "    savefig(f\"images/{file_tag}_single_boxplots.png\")\n",
    "    show()\n",
    "else:\n",
    "    print(\"There are no numeric variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "from matplotlib.pyplot import figure, savefig, show\n",
    "from dslabs_functions import plot_multibar_chart\n",
    "\n",
    "NR_STDEV: int = 2\n",
    "IQR_FACTOR: float = 1.5\n",
    "\n",
    "\n",
    "def determine_outlier_thresholds_for_var(\n",
    "    summary5: Series, std_based: bool = True, threshold: float = NR_STDEV\n",
    ") -> tuple[float, float]:\n",
    "    top: float = 0\n",
    "    bottom: float = 0\n",
    "    if std_based:\n",
    "        std: float = threshold * summary5[\"std\"]\n",
    "        top = summary5[\"mean\"] + std\n",
    "        bottom = summary5[\"mean\"] - std\n",
    "    else:\n",
    "        iqr: float = threshold * (summary5[\"75%\"] - summary5[\"25%\"])\n",
    "        top = summary5[\"75%\"] + iqr\n",
    "        bottom = summary5[\"25%\"] - iqr\n",
    "\n",
    "    return top, bottom\n",
    "\n",
    "\n",
    "def count_outliers(\n",
    "    data: DataFrame,\n",
    "    numeric: list[str],\n",
    "    nrstdev: int = NR_STDEV,\n",
    "    iqrfactor: float = IQR_FACTOR,\n",
    ") -> dict:\n",
    "    outliers_iqr: list = []\n",
    "    outliers_stdev: list = []\n",
    "    summary5: DataFrame = data[numeric].describe()\n",
    "\n",
    "    for var in numeric:\n",
    "        top: float\n",
    "        bottom: float\n",
    "        top, bottom = determine_outlier_thresholds_for_var(\n",
    "            summary5[var], std_based=True, threshold=nrstdev\n",
    "        )\n",
    "        outliers_stdev += [\n",
    "            data[data[var] > top].count()[var] + data[data[var] < bottom].count()[var]\n",
    "        ]\n",
    "\n",
    "        top, bottom = determine_outlier_thresholds_for_var(\n",
    "            summary5[var], std_based=False, threshold=iqrfactor\n",
    "        )\n",
    "        outliers_iqr += [\n",
    "            data[data[var] > top].count()[var] + data[data[var] < bottom].count()[var]\n",
    "        ]\n",
    "\n",
    "    return {\"iqr\": outliers_iqr, \"stdev\": outliers_stdev}\n",
    "\n",
    "\n",
    "if [] != numeric:\n",
    "    outliers: dict[str, int] = count_outliers(data, numeric)\n",
    "    figure(figsize=(50, HEIGHT))\n",
    "    plot_multibar_chart(\n",
    "        numeric,\n",
    "        outliers,\n",
    "        title=\"Nr of standard outliers per variable\",\n",
    "        xlabel=\"variables\",\n",
    "        ylabel=\"nr outliers\",\n",
    "        percentage=False,\n",
    "    )\n",
    "    savefig(f\"images/{file_tag}_outliers_standard.png\")\n",
    "    show()\n",
    "else:\n",
    "    print(\"There are no numeric variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dslabs_functions import set_chart_labels\n",
    "\n",
    "import math\n",
    "\n",
    "HEIGHT = 4  # Height scaling for each plot\n",
    "cols = 3    # Number of columns in the grid\n",
    "rows = math.ceil(len(numeric) / cols)  # Calculate rows based on the number of variables\n",
    "\n",
    "if [] != numeric:\n",
    "    fig, axs = subplots(\n",
    "        rows, cols, figsize=(cols * HEIGHT, rows * HEIGHT), squeeze=False\n",
    "    )\n",
    "    i: int\n",
    "    j: int\n",
    "    i, j = 0, 0\n",
    "    for n in range(len(numeric)):\n",
    "        set_chart_labels(\n",
    "            axs[i, j],\n",
    "            title=f\"Histogram for {numeric[n]}\",\n",
    "            xlabel=numeric[n],\n",
    "            ylabel=\"nr records\",\n",
    "        )\n",
    "        axs[i, j].hist(data[numeric[n]].dropna().values, \"auto\")\n",
    "        i, j = (i + 1, 0) if (n + 1) % cols == 0 else (i, j + 1)\n",
    "    savefig(f\"images/{file_tag}_single_histograms_numeric.png\")\n",
    "    show()\n",
    "else:\n",
    "    print(\"There are no numeric variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log\n",
    "from pandas import Series\n",
    "from scipy.stats import norm, expon, lognorm\n",
    "from matplotlib.axes import Axes\n",
    "from dslabs_functions import plot_multiline_chart\n",
    "\n",
    "\n",
    "def compute_known_distributions(x_values: list) -> dict:\n",
    "    distributions = dict()\n",
    "    # Gaussian\n",
    "    mean, sigma = norm.fit(x_values)\n",
    "    distributions[\"Normal(%.1f,%.2f)\" % (mean, sigma)] = norm.pdf(x_values, mean, sigma)\n",
    "    # Exponential\n",
    "    loc, scale = expon.fit(x_values)\n",
    "    distributions[\"Exp(%.2f)\" % (1 / scale)] = expon.pdf(x_values, loc, scale)\n",
    "    # LogNorm\n",
    "    sigma, loc, scale = lognorm.fit(x_values)\n",
    "    distributions[\"LogNor(%.1f,%.2f)\" % (log(scale), sigma)] = lognorm.pdf(\n",
    "        x_values, sigma, loc, scale\n",
    "    )\n",
    "    return distributions\n",
    "\n",
    "\n",
    "def histogram_with_distributions(ax: Axes, series: Series, var: str):\n",
    "    values: list = series.sort_values().to_list()\n",
    "    ax.hist(values, 20, density=True)\n",
    "    distributions: dict = compute_known_distributions(values)\n",
    "    plot_multiline_chart(\n",
    "        values,\n",
    "        distributions,\n",
    "        ax=ax,\n",
    "        title=\"Best fit for %s\" % var,\n",
    "        xlabel=var,\n",
    "        ylabel=\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "if [] != numeric:\n",
    "    fig, axs = subplots(\n",
    "        rows, cols, figsize=(cols * HEIGHT, rows * HEIGHT), squeeze=False\n",
    "    )\n",
    "    i, j = 0, 0\n",
    "    for n in range(len(numeric)):\n",
    "        histogram_with_distributions(axs[i, j], data[numeric[n]].dropna(), numeric[n])\n",
    "        i, j = (i + 1, 0) if (n + 1) % cols == 0 else (i, j + 1)\n",
    "    savefig(f\"images/{file_tag}_histogram_numeric_distribution.png\")\n",
    "    show()\n",
    "else:\n",
    "    print(\"There are no numeric variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dslabs_functions import plot_bar_chart\n",
    "\n",
    "symbolic: list[str] = variables_types[\"symbolic\"] + variables_types[\"binary\"]\n",
    "if [] != symbolic:\n",
    "    rows, cols = define_grid(len(symbolic))\n",
    "    fig, axs = subplots(\n",
    "        rows, cols, figsize=(cols * HEIGHT, rows * HEIGHT), squeeze=False\n",
    "    )\n",
    "    i, j = 0, 0\n",
    "    for n in range(len(symbolic)):\n",
    "        counts: Series = data[symbolic[n]].value_counts()\n",
    "        plot_bar_chart(\n",
    "            counts.index.to_list(),\n",
    "            counts.to_list(),\n",
    "            ax=axs[i, j],\n",
    "            title=\"Histogram for %s\" % symbolic[n],\n",
    "            xlabel=symbolic[n],\n",
    "            ylabel=\"nr records\",\n",
    "            percentage=False,\n",
    "        )\n",
    "        i, j = (i + 1, 0) if (n + 1) % cols == 0 else (i, j + 1)\n",
    "    savefig(f\"images/{file_tag}_histograms_symbolic.png\")\n",
    "    show()\n",
    "else:\n",
    "    print(\"There are no symbolic variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"CLASS\"\n",
    "\n",
    "values: Series = data[target].value_counts()\n",
    "print(values)\n",
    "\n",
    "figure(figsize=(4, 2))\n",
    "plot_bar_chart(\n",
    "    values.index.to_list(),\n",
    "    values.to_list(),\n",
    "    title=f\"Target distribution (target={target})\",\n",
    ")\n",
    "savefig(f\"images/{file_tag}_class_distribution.png\")\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bh-vbTTVMKwr"
   },
   "source": [
    "## Sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "from pandas import read_csv, DataFrame\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.pyplot import figure, subplots, savefig, show\n",
    "from dslabs_functions import HEIGHT, plot_multi_scatters_chart\n",
    "\n",
    "vars: list = data.columns.to_list()\n",
    "if [] != vars:\n",
    "    target = \"CLASS\"\n",
    "\n",
    "    n: int = len(vars) - 1\n",
    "    fig: Figure\n",
    "    axs: ndarray\n",
    "    fig, axs = subplots(n, n, figsize=(n * HEIGHT, n * HEIGHT), squeeze=False)\n",
    "    for i in range(len(vars)):\n",
    "        var1: str = vars[i]\n",
    "        for j in range(i + 1, len(vars)):\n",
    "            var2: str = vars[j]\n",
    "            plot_multi_scatters_chart(data, var1, var2, ax=axs[i, j - 1])\n",
    "    savefig(f\"images/{file_tag}_sparsity_study.png\")\n",
    "    show()\n",
    "else:\n",
    "    print(\"Sparsity class: there are no variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next code is the right one, I think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [] != vars:fjjffh\n",
    "    target = \"CLASS\"\n",
    "\n",
    "    n: int = len(vars) - 1\n",
    "    fig, axs = subplots(n, n, figsize=(n * HEIGHT, n * HEIGHT), squeeze=False)\n",
    "    for i in range(len(vars)):\n",
    "        var1: str = vars[i]\n",
    "        for j in range(i + 1, len(vars)):\n",
    "            var2: str = vars[j]\n",
    "            plot_multi_scatters_chart(data, var1, var2, target, ax=axs[i, j - 1])\n",
    "    savefig(f\"images/{file_tag}_sparsity_per_class_study.png\")\n",
    "    show()\n",
    "else:\n",
    "    print(\"Sparsity per class: there are no variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import heatmap\n",
    "from matplotlib.pyplot import figure, savefig, show\n",
    "from dslabs_functions import get_variable_types\n",
    "\n",
    "# Define your target variable\n",
    "target = \"CLASS\"  # Replace with the actual name of your target variable\n",
    "\n",
    "# Get numeric variable types\n",
    "variables_types: dict[str, list] = get_variable_types(data)\n",
    "numeric: list[str] = variables_types[\"numeric\"]\n",
    "\n",
    "# Add the target variable to the numeric list if it's not already included\n",
    "if target not in numeric:\n",
    "    numeric.append(target)\n",
    "\n",
    "# Compute correlation matrix (including the target)\n",
    "corr_mtx: DataFrame = data[numeric].corr().abs()\n",
    "\n",
    "# Set figure size for better readability\n",
    "figure(figsize=(15, 15))  # Adjust width and height as needed\n",
    "heatmap(\n",
    "    corr_mtx,\n",
    "    xticklabels=numeric,\n",
    "    yticklabels=numeric,\n",
    "    fmt=\".2f\",           # Format numbers to 2 decimal places\n",
    "    annot=True,          # Display correlation values\n",
    "    cmap=\"Blues\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    square=True,         # Ensures cells are square\n",
    "    cbar_kws={\"shrink\": 0.75},  # Adjust color bar size\n",
    "    annot_kws={\"size\": 3},      # Adjust font size for annotations\n",
    ")\n",
    "\n",
    "# Save and display the heatmap\n",
    "savefig(f\"images/{file_tag}_correlation_analysis_with_target.png\", dpi=300)  # Increase DPI for higher resolution\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 02 - Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dslabs_functions import *\n",
    "\n",
    "from pandas import read_csv, DataFrame\n",
    "\n",
    "filename = \"data/CFD.csv\"\n",
    "target = \"CLASS\"\n",
    "file_tag = \"CFD\"\n",
    "file = \"CFD\"\n",
    "data: DataFrame = read_csv(filename, na_values=\"\")\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame, Series\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "file = \"CFD\"\n",
    "target = \"CLASS\"\n",
    "vars: list[str] = data.columns.to_list()\n",
    "print(len(vars))\n",
    "data_copy = data.copy(deep=True)\n",
    "target_data: Series = data_copy.pop(target)\n",
    "\n",
    "transf: StandardScaler = StandardScaler(with_mean=True, with_std=True, copy=True).fit(\n",
    "    data_copy\n",
    ")\n",
    "df_zscore = DataFrame(transf.transform(data_copy), index=data_copy.index)\n",
    "df_zscore[target] = target_data\n",
    "df_zscore.columns = vars\n",
    "df_zscore.to_csv(f\"data/{file}_scaled_zscore.csv\", index=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "transf: MinMaxScaler = MinMaxScaler(feature_range=(0, 1), copy=True).fit(data)\n",
    "df_minmax = DataFrame(transf.transform(data), index=data.index)\n",
    "df_minmax.columns = vars\n",
    "df_minmax[target] = target_data\n",
    "df_minmax.to_csv(f\"data/{file}_scaled_minmax.csv\", index=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to train and test\n",
    "data = df_minmax\n",
    "train = data.sample(frac=0.8, random_state=42)\n",
    "test = data.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "from pandas import DataFrame, read_csv\n",
    "from matplotlib.pyplot import savefig, show, figure\n",
    "from dslabs_functions import plot_multibar_chart, CLASS_EVAL_METRICS, run_NB, run_KNN\n",
    "\n",
    "\n",
    "def evaluate_approach(\n",
    "\ttrain: DataFrame, test: DataFrame, target: str = \"class\", metric: str = \"accuracy\"\n",
    ") -> dict[str, list]:\n",
    "\ttrnY = train.pop(target).values\n",
    "\ttrnX: ndarray = train.values\n",
    "\ttstY = test.pop(target).values\n",
    "\ttstX: ndarray = test.values\n",
    "\teval: dict[str, list] = {}\n",
    "\n",
    "\teval_NB: dict[str, float] = run_NB(trnX, trnY, tstX, tstY, metric=metric)\n",
    "\teval_KNN: dict[str, float] = run_KNN(trnX, trnY, tstX, tstY, metric=metric)\n",
    "\tif eval_NB != {} and eval_KNN != {}:\n",
    "\t\tfor met in CLASS_EVAL_METRICS:\n",
    "\t\t\teval[met] = [eval_NB[met], eval_KNN[met]]\n",
    "\treturn eval\n",
    "\n",
    "figure()\n",
    "\n",
    "def results(train, test, name=\"eval\"):\n",
    "\teval: dict[str, list] = evaluate_approach(train, test, target=target, metric=\"recall\")\n",
    "\tplot_multibar_chart(\n",
    "\t\t[\"NB\", \"KNN\"], eval, title=f\"{file_tag} evaluation\", percentage=True\n",
    "\t)\n",
    "\tsavefig(f\"images/{file_tag}_{name}.png\")\n",
    "\tshow()\n",
    "\n",
    "results(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable encoding\n",
    "\n",
    "#### We only have 1 binary class\n",
    "\n",
    "#### Ask for cyclic variables in TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "from dslabs_functions import get_variable_types, encode_cyclic_variables, dummify\n",
    "\n",
    "vars: dict[str, list] = get_variable_types(data)\n",
    "\n",
    "yes_no: dict[str, int] = {\"no\": 0, \"No\": 0, \"yes\": 1, \"Yes\": 1}\n",
    "\n",
    "\n",
    "encoding: dict[str, dict[str, int]] = {\n",
    "    \"CLASS\": yes_no,\n",
    "}\n",
    "df: DataFrame = data.replace(encoding, inplace=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values Imputation\n",
    "\n",
    "### We do not have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "from matplotlib.pyplot import figure, show\n",
    "from dslabs_functions import plot_bar_chart\n",
    "\n",
    "print(f\"Dataset nr records={data.shape[0]}\", f\"nr variables={data.shape[1]}\")\n",
    "\n",
    "mv: dict[str, int] = {}\n",
    "figure()\n",
    "for var in data:\n",
    "    nr: int = data[var].isna().sum()\n",
    "    if nr > 0:\n",
    "        mv[var] = nr\n",
    "\n",
    "plot_bar_chart(\n",
    "    list(mv.keys()),\n",
    "    list(mv.values()),\n",
    "    title=\"Missing values per variable\",\n",
    "    xlabel=\"variables\",\n",
    "    ylabel=\"nr missing values\",\n",
    ")\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame, Series\n",
    "from dslabs_functions import (\n",
    "    NR_STDEV,\n",
    "    get_variable_types,\n",
    "    determine_outlier_thresholds_for_var,\n",
    ")\n",
    "\n",
    "print(f\"Original data: {data.shape}\")\n",
    "\n",
    "n_std: int = NR_STDEV\n",
    "numeric_vars: list[str] = get_variable_types(data)[\"numeric\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numeric_vars is not None:\n",
    "    df: DataFrame = data.copy(deep=True)\n",
    "    summary5: DataFrame = data[numeric_vars].describe()\n",
    "    for var in numeric_vars:\n",
    "        top_threshold, bottom_threshold = determine_outlier_thresholds_for_var(\n",
    "            summary5[var]\n",
    "        )\n",
    "        outliers: Series = df[(df[var] > top_threshold) | (df[var] < bottom_threshold)]\n",
    "        df.drop(outliers.index, axis=0, inplace=True)\n",
    "    df.to_csv(f\"data/{file_tag}_drop_outliers.csv\", index=True)\n",
    "    print(f\"Data after dropping outliers: {df.shape}\")\n",
    "else:\n",
    "    print(\"There are no numeric variables\")\n",
    "\n",
    "def drop_outliers_features():\n",
    "    nr_outliers = count_outliers(data, numeric_vars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace outliers with fixed value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [] != numeric_vars:\n",
    "    df: DataFrame = data.copy(deep=True)\n",
    "    for var in numeric_vars:\n",
    "        top, bottom = determine_outlier_thresholds_for_var(summary5[var])\n",
    "        median: float = df[var].median()\n",
    "        df[var] = df[var].apply(lambda x: median if x > top or x < bottom else x)\n",
    "    df.to_csv(f\"data/{file_tag}_replacing_outliers.csv\", index=True)\n",
    "    print(\"Data after replacing outliers:\", df.shape)\n",
    "    # print(df.describe())\n",
    "else:\n",
    "    print(\"There are no numeric variables\")\n",
    "\n",
    "# Split the data to train and test\n",
    "train = df.sample(frac=0.8, random_state=42)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "results(train, test, \"replace_outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncating outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if [] != numeric_vars:\n",
    "    df: DataFrame = data.copy(deep=True)\n",
    "    for var in numeric_vars:\n",
    "        top, bottom = determine_outlier_thresholds_for_var(summary5[var])\n",
    "        df[var] = df[var].apply(\n",
    "            lambda x: top if x > top else bottom if x < bottom else x\n",
    "        )\n",
    "    df.to_csv(f\"data/{file_tag}_truncate_outliers.csv\", index=True)\n",
    "    print(\"Data after truncating outliers:\", df.shape)\n",
    "    # print(df.describe())\n",
    "else:\n",
    "    print(\"There are no numeric variables\")\n",
    "\n",
    "# Split the data to train and test\n",
    "train = df.sample(frac=0.8, random_state=42)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "results(train, test, \"truncate_outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame, Series\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "vars: list[str] = data.columns.to_list()\n",
    "\n",
    "# Make a full copy of the data\n",
    "data_copy = data.copy(deep=True)\n",
    "print(data.shape)\n",
    "target_data: Series = data_copy.pop(target)\n",
    "print(data.shape)\n",
    "print(data_copy.shape)\n",
    "\n",
    "transf: StandardScaler = StandardScaler(with_mean=True, with_std=True, copy=True).fit(\n",
    "    data_copy\n",
    ")\n",
    "df_zscore = DataFrame(transf.transform(data_copy), index=data_copy.index)\n",
    "df_zscore[target] = target_data\n",
    "df_zscore.columns = vars\n",
    "df_zscore.to_csv(f\"data/{file}_scaled_zscore.csv\", index=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "transf: MinMaxScaler = MinMaxScaler(feature_range=(0, 1), copy=True).fit(data)\n",
    "df_minmax = DataFrame(transf.transform(data), index=data.index)\n",
    "df_minmax.columns = vars\n",
    "df_minmax[target] = target_data\n",
    "df_minmax.to_csv(f\"data/{file}_scaled_minmax.csv\", index=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import subplots, show\n",
    "\n",
    "fig, axs = subplots(1, 3, figsize=(20, 10), squeeze=False)\n",
    "axs[0, 1].set_title(\"Original data\")\n",
    "data.boxplot(ax=axs[0, 0])\n",
    "axs[0, 0].set_title(\"Z-score normalization\")\n",
    "df_zscore.boxplot(ax=axs[0, 1])\n",
    "axs[0, 2].set_title(\"MinMax normalization\")\n",
    "df_minmax.boxplot(ax=axs[0, 2])\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO-DO - Adapt the code to our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, concat, DataFrame, Series\n",
    "from matplotlib.pyplot import figure, show\n",
    "from dslabs_functions import plot_bar_chart\n",
    "\n",
    "file = \"stroke_train\"\n",
    "target = \"stroke\"\n",
    "original: DataFrame = read_csv(f\"data/{file}.csv\", sep=\",\", decimal=\".\")\n",
    "\n",
    "target_count: Series = original[target].value_counts()\n",
    "positive_class = target_count.idxmin()\n",
    "negative_class = target_count.idxmax()\n",
    "\n",
    "print(\"Minority class=\", positive_class, \":\", target_count[positive_class])\n",
    "print(\"Majority class=\", negative_class, \":\", target_count[negative_class])\n",
    "print(\n",
    "    \"Proportion:\",\n",
    "    round(target_count[positive_class] / target_count[negative_class], 2),\n",
    "    \": 1\",\n",
    ")\n",
    "values: dict[str, list] = {\n",
    "    \"Original\": [target_count[positive_class], target_count[negative_class]]\n",
    "}\n",
    "\n",
    "figure()\n",
    "plot_bar_chart(\n",
    "    target_count.index.to_list(), target_count.to_list(), title=\"Class balance\"\n",
    ")\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positives: Series = original[original[target] == positive_class]\n",
    "df_negatives: Series = original[original[target] == negative_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_neg_sample: DataFrame = DataFrame(df_negatives.sample(len(df_positives)))\n",
    "df_under: DataFrame = concat([df_positives, df_neg_sample], axis=0)\n",
    "df_under.to_csv(f\"data/{file}_under.csv\", index=False)\n",
    "\n",
    "print(\"Minority class=\", positive_class, \":\", len(df_positives))\n",
    "print(\"Majority class=\", negative_class, \":\", len(df_neg_sample))\n",
    "print(\"Proportion:\", round(len(df_positives) / len(df_neg_sample), 2), \": 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos_sample: DataFrame = DataFrame(\n",
    "    df_positives.sample(len(df_negatives), replace=True)\n",
    ")\n",
    "df_over: DataFrame = concat([df_pos_sample, df_negatives], axis=0)\n",
    "df_over.to_csv(f\"data/{file}_over.csv\", index=False)\n",
    "\n",
    "print(\"Minority class=\", positive_class, \":\", len(df_pos_sample))\n",
    "print(\"Majority class=\", negative_class, \":\", len(df_negatives))\n",
    "print(\"Proportion:\", round(len(df_pos_sample) / len(df_negatives), 2), \": 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "from pandas import Series\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "smote: SMOTE = SMOTE(sampling_strategy=\"minority\", random_state=RANDOM_STATE)\n",
    "y = original.pop(target).values\n",
    "X: ndarray = original.values\n",
    "smote_X, smote_y = smote.fit_resample(X, y)\n",
    "df_smote: DataFrame = concat([DataFrame(smote_X), DataFrame(smote_y)], axis=1)\n",
    "df_smote.columns = list(original.columns) + [target]\n",
    "df_smote.to_csv(f\"data/{file}_smote.csv\", index=False)\n",
    "\n",
    "smote_target_count: Series = Series(smote_y).value_counts()\n",
    "print(\"Minority class=\", positive_class, \":\", smote_target_count[positive_class])\n",
    "print(\"Majority class=\", negative_class, \":\", smote_target_count[negative_class])\n",
    "print(\n",
    "    \"Proportion:\",\n",
    "    round(smote_target_count[positive_class] / smote_target_count[negative_class], 2),\n",
    "    \": 1\",\n",
    ")\n",
    "print(df_smote.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "\n",
    "file = \"algae\"\n",
    "filename = \"data/algae_mv_most_frequent.csv\"\n",
    "data: DataFrame = read_csv(\n",
    "    filename,\n",
    "    index_col=\"date\",\n",
    "    na_values=\"\",\n",
    "    parse_dates=True,\n",
    ")\n",
    "\n",
    "from dslabs_functions import get_variable_types\n",
    "\n",
    "variable_types: dict[str, list] = get_variable_types(data)\n",
    "numeric_vars: list[str] = variable_types[\"numeric\"]\n",
    "symbolic_vars: list[str] = variable_types[\"symbolic\"]\n",
    "boolean_vars: list[str] = variable_types[\"binary\"]\n",
    "\n",
    "df_nr: DataFrame = data[numeric_vars]\n",
    "df_sb: DataFrame = data[symbolic_vars]\n",
    "df_bool = data[boolean_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal-width "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from pandas import concat\n",
    "\n",
    "N_BINS = 5\n",
    "discretization: KBinsDiscretizer = KBinsDiscretizer(\n",
    "    n_bins=N_BINS, encode=\"ordinal\", strategy=\"uniform\"\n",
    ")\n",
    "discretization.fit(df_nr)\n",
    "eq_width = DataFrame(discretization.transform(df_nr), index=data.index)\n",
    "\n",
    "df = DataFrame(df_sb, index=data.index)\n",
    "df: DataFrame = concat([df, df_bool, eq_width], axis=1)\n",
    "df.columns = symbolic_vars + boolean_vars + numeric_vars\n",
    "df.to_csv(f\"data/{file}_eq_width.csv\", index=True)\n",
    "\n",
    "df.hist(bins=N_BINS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal-frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretization: KBinsDiscretizer = KBinsDiscretizer(\n",
    "    n_bins=N_BINS, encode=\"ordinal\", strategy=\"quantile\"\n",
    ")\n",
    "discretization.fit(df_nr)\n",
    "eq_width = DataFrame(discretization.transform(df_nr), index=data.index)\n",
    "\n",
    "df = DataFrame(df_sb, index=data.index)\n",
    "df = concat([df, df_bool, eq_width], axis=1)\n",
    "df.columns = symbolic_vars + boolean_vars + numeric_vars\n",
    "df.to_csv(f\"data/{file}_eq_frequency.csv\", index=True)\n",
    "\n",
    "df.hist(bins=N_BINS)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
